# ğŸ“Š Analyse de Performance des Bases de DonnÃ©es

Projet d'analyse et d'optimisation des performances de bases de donnÃ©es relationnelles (PostgreSQL) et NoSQL (MongoDB) dans le cadre du MastÃ¨re SpÃ©cialisÃ© en Big Data.

---

## ğŸ“ Structure du Projet

```
database-performance-analysis/
â”œâ”€â”€ tp1/              # Analyse de performance PostgreSQL (schÃ©ma de cinÃ©ma)
â””â”€â”€ tp2/              # Analyse comparative SQL/NoSQL (trading Binance)
```

---

## ğŸ¯ TP1 : Performance des Bases de DonnÃ©es Relationnelles

### Objectif
Analyser et optimiser les performances d'une base de donnÃ©es PostgreSQL Ã  l'aide de requÃªtes SQL rÃ©alistes, de plans d'exÃ©cution et de techniques d'indexation.

### ThÃ¨me
Gestion d'un systÃ¨me de **rÃ©servation de cinÃ©ma** avec :
- Gestion des films et des sÃ©ances
- RÃ©servations de places
- Gestion des salles et des tarifs
- Analyse des ventes

### Technologies
- **PostgreSQL** (base de donnÃ©es relationnelle)
- **Docker** (conteneurisation)
- **SQL** (manipulation et analyse des donnÃ©es)

### Contenu
- âœ… Conception du schÃ©ma de base de donnÃ©es
- âœ… GÃ©nÃ©ration de donnÃ©es volumineuses (mock data)
- âœ… Analyse des requÃªtes avec EXPLAIN / ANALYZE
- âœ… Optimisation par indexation
- âœ… Mesure des gains de performance

### Structure
```
tp1/
â”œâ”€â”€ sql/              # Scripts SQL (crÃ©ation, insertion, requÃªtes)
â”œâ”€â”€ docs/             # Documentation du projet
â”œâ”€â”€ images/           # Captures d'Ã©cran et schÃ©mas
â””â”€â”€ docker-compose.yml
```

### ExÃ©cution
```bash
cd tp1
docker compose up -d
# Lancer les scripts SQL dans l'ordre prÃ©sent dans le dossier sql/
```

---

## ğŸš€ TP2 : Analyse Comparative SQL vs NoSQL

### Objectif
Mettre en place et optimiser une plateforme d'analyse de donnÃ©es issues d'une API publique (Binance) pour :
- Structurer efficacement les donnÃ©es
- Optimiser les requÃªtes analytiques
- Comparer les approches SQL et NoSQL
- Mesurer objectivement les gains de performance

### ThÃ¨me
Analyse des **trades en temps rÃ©el** depuis l'API Binance (BTCUSDT) avec :
- Collecte de 1 000 000 de trades
- Stockage dual : PostgreSQL + MongoDB
- Optimisation avancÃ©e (index, vues matÃ©rialisÃ©es, partitioning)
- Comparaison de performance SQL vs NoSQL

### Technologies
- **PostgreSQL 15-alpine** (base de donnÃ©es relationnelle)
- **MongoDB Atlas** (base de donnÃ©es NoSQL cloud)
- **Python 3.13** (ETL et scripts d'analyse)
- **Docker** (conteneurisation PostgreSQL)
- **Binance API** (source de donnÃ©es rÃ©elles)

### ğŸ“‹ Les 4 Phases du Projet

#### **PHASE 1 : Mise en place des donnÃ©es** âœ…
- Script Python de collecte depuis l'API Binance
- Stockage des donnÃ©es brutes dans MongoDB (JSON)
- Stockage structurÃ© dans PostgreSQL (tables normalisÃ©es + partitioning)
- **RÃ©sultat** : 1 000 000 trades collectÃ©s en ~40 minutes (407 trades/sec)

#### **PHASE 2 : Diagnostic des performances SQL** âœ…
- Analyse de 6 types de requÃªtes mÃ©tier (filtres, tris, GROUP BY, JOIN)
- Utilisation de EXPLAIN (ANALYZE, BUFFERS)
- Identification des Sequential Scans et des manques d'index
- **RÃ©sultat** : RequÃªtes entre 48ms et 204ms sans optimisation

#### **PHASE 3 : Optimisation avancÃ©e SQL** âœ…
- CrÃ©ation de 7 index B-tree (price, quantity, composÃ©s)
- 2 vues matÃ©rialisÃ©es (statistiques horaires et par symbole)
- ANALYZE des tables pour mise Ã  jour des statistiques
- **RÃ©sultats** :
  - Filtre sur price : 165ms â†’ **0.18ms** (Ã— 920)
  - Tri sur quantity : 169ms â†’ **0.82ms** (Ã— 205)
  - Stats horaires : 204ms â†’ **0.13ms** (Ã— 1600)
  - Stats par symbole : 203ms â†’ **0.12ms** (Ã— 1690)

#### **PHASE 4 : Optimisation MongoDB** âœ…
- Analyse AVANT optimisation (COLLSCAN)
- CrÃ©ation de 4 index (price, timestamp, quantity, composÃ©)
- Analyse APRÃˆS optimisation (IXSCAN)
- Tests avec Aggregation Pipeline
- **RÃ©sultats** :
  - Filtre sur price : 687ms â†’ **79ms** (Ã— 8.6)
  - MongoDB reste **440Ã— plus lent** que PostgreSQL optimisÃ©

### Structure
```
tp2/
â”œâ”€â”€ python/
â”‚   â”œâ”€â”€ collect_data.py           # ETL Binance â†’ PostgreSQL + MongoDB
â”‚   â””â”€â”€ mongodb_optimization.py   # Tests de performance MongoDB
â”œâ”€â”€ sql/
â”‚   â”œâ”€â”€ create-table.sql          # SchÃ©ma PostgreSQL (partitioned)
â”‚   â”œâ”€â”€ diagnostic-queries.sql    # RequÃªtes d'analyse
â”‚   â””â”€â”€ optimizations.sql         # Index + vues matÃ©rialisÃ©es
â”œâ”€â”€ doc/
â”‚   â”œâ”€â”€ instruction-second-task.md   # Consignes du projet
â”‚   â”œâ”€â”€ analyse-request.md           # Analyse dÃ©taillÃ©e Phase 2
â”‚   â”œâ”€â”€ comparaison-avant-apres.md   # RÃ©sultats Phase 3
â”‚   â””â”€â”€ mongodb-optimisation.md      # RÃ©sultats Phase 4
â”œâ”€â”€ docker-compose.yml            # PostgreSQL container
â””â”€â”€ venv/                         # Environnement Python
```

### ExÃ©cution

#### 1. DÃ©marrer PostgreSQL
```bash
cd tp2
docker compose up -d
```

#### 2. CrÃ©er l'environnement Python
```bash
python3 -m venv venv
source venv/bin/activate  # macOS/Linux
pip install requests psycopg2-binary pymongo certifi
```

#### 3. CrÃ©er le schÃ©ma PostgreSQL
```bash
docker exec -i postgres_trading psql -U admin -d trading_db < sql/create-table.sql
```

#### 4. Collecter les donnÃ©es (Phase 1)
```bash
python python/collect_data.py
# Collecte 1M trades depuis Binance (~ 40 min)
```

#### 5. Appliquer les optimisations (Phase 3)
```bash
docker exec -i postgres_trading psql -U admin -d trading_db < sql/optimizations.sql
```

#### 6. Tester MongoDB (Phase 4)
```bash
python python/mongodb_optimization.py
```

---

## ğŸ“Š RÃ©sultats Comparatifs

### PostgreSQL vs MongoDB (aprÃ¨s optimisation)

| Type de RequÃªte | PostgreSQL | MongoDB | Gagnant |
|-----------------|------------|---------|---------|
| **Filtre sur prix** | 0.18 ms | 79 ms | PostgreSQL (Ã— 440) |
| **Tri + LIMIT** | 0.82 ms | - | PostgreSQL |
| **Statistiques globales** | 0.12 ms (MV) | - | PostgreSQL |
| **Gain d'optimisation** | Ã— 920 | Ã— 8.6 | PostgreSQL |

### ğŸ† Conclusions

#### PostgreSQL excelle pour :
- âœ… RequÃªtes analytiques complexes (JOIN, GROUP BY)
- âœ… Performance extrÃªme avec vues matÃ©rialisÃ©es
- âœ… IntÃ©gritÃ© rÃ©fÃ©rentielle et transactions ACID
- âœ… Optimisations avancÃ©es (index B-tree, partitioning)

#### MongoDB excelle pour :
- âœ… SchÃ©ma flexible et Ã©volutif
- âœ… Stockage de JSON brut
- âœ… ScalabilitÃ© horizontale (sharding)
- âœ… RequÃªtes sur documents imbriquÃ©s

---

## ğŸ› ï¸ Technologies UtilisÃ©es

| Technologie | Version | Usage |
|-------------|---------|-------|
| **PostgreSQL** | 15-alpine | Base de donnÃ©es relationnelle |
| **MongoDB Atlas** | Cloud | Base de donnÃ©es NoSQL |
| **Python** | 3.13 | Scripts ETL et analyse |
| **Docker** | Latest | Conteneurisation |
| **psycopg2-binary** | 2.9.11 | Driver PostgreSQL |
| **pymongo** | 4.16.0 | Driver MongoDB |
| **requests** | 2.32.5 | Appels API Binance |
| **certifi** | 2026.1.4 | Certificats SSL MongoDB |

---

## ğŸ“– Documentation

### TP1
- [README.md](tp1/README.md) - Vue d'ensemble du projet
- Documentation SQL dans `tp1/docs/`

### TP2
- [instruction-second-task.md](tp2/doc/instruction-second-task.md) - Consignes du projet
- [analyse-request.md](tp2/doc/analyse-request.md) - Analyse Phase 2 (diagnostic)
- [comparaison-avant-apres.md](tp2/doc/comparaison-avant-apres.md) - RÃ©sultats Phase 3 (SQL)
- [mongodb-optimisation.md](tp2/doc/mongodb-optimisation.md) - RÃ©sultats Phase 4 (NoSQL)

---

## ğŸ‘¨â€ğŸ’» Auteur

**Lucas**  
MastÃ¨re SpÃ©cialisÃ© Big Data - Bordeaux Ynov Campus  
Janvier 2026

---

## ğŸ“ Licence

Projet acadÃ©mique - Tous droits rÃ©servÃ©s
