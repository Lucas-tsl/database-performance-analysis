# üìä Analyse de Performance des Bases de Donn√©es

Projet d'analyse et d'optimisation des performances de bases de donn√©es relationnelles (PostgreSQL) et NoSQL (MongoDB) dans le cadre du Mast√®re Sp√©cialis√© en Big Data.

---

---

## üéØ TP1 : Performance des Bases de Donn√©es Relationnelles

### Objectif
Analyser et optimiser les performances d'une base de donn√©es PostgreSQL √† l'aide de requ√™tes SQL r√©alistes, de plans d'ex√©cution et de techniques d'indexation.

### Th√®me
Gestion d'un syst√®me de **r√©servation de cin√©ma** avec :
- Gestion des films et des s√©ances
- R√©servations de places
- Gestion des salles et des tarifs
- Analyse des ventes



### Ex√©cution
```bash
cd tp1
docker compose up -d
# Lancer les scripts SQL dans l'ordre pr√©sent dans le dossier sql/
```

---

## üöÄ TP2 : Analyse Comparative SQL vs NoSQL

### Objectif
Mettre en place et optimiser une plateforme d'analyse de donn√©es issues d'une API publique (Binance) pour :
- Structurer efficacement les donn√©es
- Optimiser les requ√™tes analytiques
- Comparer les approches SQL et NoSQL
- Mesurer objectivement les gains de performance

### Th√®me
Analyse des **trades en temps r√©el** depuis l'API Binance (BTCUSDT) avec :
- Collecte de 1 000 000 de trades
- Stockage dual : PostgreSQL + MongoDB
- Optimisation avanc√©e (index, vues mat√©rialis√©es, partitioning)
- Comparaison de performance SQL vs NoSQL


### üìã Les 4 Phases du Projet

#### **PHASE 1 : Mise en place des donn√©es** ‚úÖ
- Script Python de collecte depuis l'API Binance
- Stockage des donn√©es brutes dans MongoDB (JSON)
- Stockage structur√© dans PostgreSQL (tables normalis√©es + partitioning)
- **R√©sultat** : 1 000 000 trades collect√©s en ~40 minutes (407 trades/sec)

#### **PHASE 2 : Diagnostic des performances SQL** ‚úÖ
- Analyse de 6 types de requ√™tes m√©tier (filtres, tris, GROUP BY, JOIN)
- Utilisation de EXPLAIN (ANALYZE, BUFFERS)
- Identification des Sequential Scans et des manques d'index
- **R√©sultat** : Requ√™tes entre 48ms et 204ms sans optimisation

#### **PHASE 3 : Optimisation avanc√©e SQL** ‚úÖ
- Cr√©ation de 7 index B-tree (price, quantity, compos√©s)
- 2 vues mat√©rialis√©es (statistiques horaires et par symbole)
- ANALYZE des tables pour mise √† jour des statistiques
- **R√©sultats** :
  - Filtre sur price : 165ms ‚Üí **0.18ms** (√ó 920)
  - Tri sur quantity : 169ms ‚Üí **0.82ms** (√ó 205)
  - Stats horaires : 204ms ‚Üí **0.13ms** (√ó 1600)
  - Stats par symbole : 203ms ‚Üí **0.12ms** (√ó 1690)

#### **PHASE 4 : Optimisation MongoDB** ‚úÖ
- Analyse AVANT optimisation (COLLSCAN)
- Cr√©ation de 4 index (price, timestamp, quantity, compos√©)
- Analyse APR√àS optimisation (IXSCAN)
- Tests avec Aggregation Pipeline
- **R√©sultats** :
  - Filtre sur price : 687ms ‚Üí **79ms** (√ó 8.6)
  - MongoDB reste **440√ó plus lent** que PostgreSQL optimis√©

### Ex√©cution

#### 1. D√©marrer PostgreSQL
```bash
cd tp2
docker compose up -d
```

#### 2. Cr√©er l'environnement Python
```bash
python3 -m venv venv
source venv/bin/activate  # macOS/Linux
pip install requests psycopg2-binary pymongo certifi
```

#### 3. Cr√©er le sch√©ma PostgreSQL
```bash
docker exec -i postgres_trading psql -U admin -d trading_db < sql/create-table.sql
```

#### 4. Collecter les donn√©es (Phase 1)
```bash
python python/collect_data.py
# Collecte 1M trades depuis Binance (~ 40 min)
```

#### 5. Appliquer les optimisations (Phase 3)
```bash
docker exec -i postgres_trading psql -U admin -d trading_db < sql/optimizations.sql
```

#### 6. Tester MongoDB (Phase 4)
```bash
python python/mongodb_optimization.py
```

---

## üìä R√©sultats Comparatifs

### PostgreSQL vs MongoDB (apr√®s optimisation)

| Type de Requ√™te | PostgreSQL | MongoDB | Gagnant |
|-----------------|------------|---------|---------|
| **Filtre sur prix** | 0.18 ms | 79 ms | PostgreSQL (√ó 440) |
| **Tri + LIMIT** | 0.82 ms | - | PostgreSQL |
| **Statistiques globales** | 0.12 ms (MV) | - | PostgreSQL || **Gain d'optimisation** | √ó 920 | √ó 8.6 | PostgreSQL |

## üõ†Ô∏è Technologies Utilis√©es

| Technologie | Version | Usage |
|-------------|---------|-------|
| **PostgreSQL** | 15-alpine | Base de donn√©es relationnelle |
| **MongoDB Atlas** | Cloud | Base de donn√©es NoSQL |
| **Python** | 3.13 | Scripts ETL et analyse |
| **Docker** | Latest | Conteneurisation |
| **psycopg2-binary** | 2.9.11 | Driver PostgreSQL |
| **pymongo** | 4.16.0 | Driver MongoDB |
| **requests** | 2.32.5 | Appels API Binance |
| **certifi** | 2026.1.4 | Certificats SSL MongoDB |

---

## üìñ Documentation

### TP1
- [README.md](tp1/README.md) - Vue d'ensemble du projet
- Documentation SQL dans `tp1/docs/`

### TP2
- [instruction-second-task.md](tp2/doc/instruction-second-task.md) - Consignes du projet
- [analyse-request.md](tp2/doc/analyse-request.md) - Analyse Phase 2 (diagnostic)
- [comparaison-avant-apres.md](tp2/doc/comparaison-avant-apres.md) - R√©sultats Phase 3 (SQL)
- [mongodb-optimisation.md](tp2/doc/mongodb-optimisation.md) - R√©sultats Phase 4 (NoSQL)

---

## üë®‚Äçüíª Auteur

**Lucas**  
Mast√®re Sp√©cialis√© Big Data - Bordeaux Ynov Campus  
Janvier 2026

---

## üìù Licence

Projet acad√©mique - Tous droits r√©serv√©s
